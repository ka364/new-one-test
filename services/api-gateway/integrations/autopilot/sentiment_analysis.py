"""

Sentiment Analysis for HaderOS

ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± ÙÙŠ Ø§Ù„Ù†ØµÙˆØµ Ù„ÙÙ‡Ù… Ø¢Ø±Ø§Ø¡ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ ÙˆØªØ­Ø³ÙŠÙ† Ø§Ù„Ø®Ø¯Ù…Ø§Øª.

"""

import asyncio
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime
from dataclasses import dataclass
from enum import Enum
import structlog

try:
    from textblob import TextBlob
    TEXTBLOB_AVAILABLE = True
except ImportError:
    TEXTBLOB_AVAILABLE = False
    print("âš ï¸ TextBlob ØºÙŠØ± Ù…ØªÙˆÙØ±. Ù‚Ù… Ø¨ØªØ«Ø¨ÙŠØªÙ‡: pip install textblob")

from services.api_gateway.core.database import get_redis

logger = structlog.get_logger(__name__)


class SentimentType(Enum):
    """Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±"""
    POSITIVE = "positive"
    NEGATIVE = "negative"
    NEUTRAL = "neutral"


@dataclass
class SentimentResult:
    """Ù†ØªÙŠØ¬Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±"""
    text: str
    sentiment: SentimentType
    polarity: float  # Ù…Ù† -1 (Ø³Ù„Ø¨ÙŠ) Ø¥Ù„Ù‰ 1 (Ø¥ÙŠØ¬Ø§Ø¨ÙŠ)
    subjectivity: float  # Ù…Ù† 0 (Ù…ÙˆØ¶ÙˆØ¹ÙŠ) Ø¥Ù„Ù‰ 1 (Ø°Ø§ØªÙŠ)
    confidence: float
    timestamp: datetime
    source: str  # Ù…ØµØ¯Ø± Ø§Ù„Ù†Øµ (Ù…Ø«Ù„: shopify_review, aramex_feedback)


@dataclass
class SentimentMetrics:
    """Ù…Ù‚Ø§ÙŠÙŠØ³ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±"""
    total_analyzed: int = 0
    positive_count: int = 0
    negative_count: int = 0
    neutral_count: int = 0
    average_polarity: float = 0.0
    average_subjectivity: float = 0.0
    last_updated: datetime = None

    def __post_init__(self):
        if self.last_updated is None:
            self.last_updated = datetime.utcnow()


class SentimentAnalyzer:
    """Ù…Ø­Ù„Ù„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±"""

    def __init__(self):
        self.metrics = SentimentMetrics()
        self.analysis_history: List[SentimentResult] = []
        self.is_initialized = False

    async def initialize_sentiment_analyzer(self):
        """ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ù„Ù„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±"""
        if not TEXTBLOB_AVAILABLE:
            logger.error("TextBlob ØºÙŠØ± Ù…ØªÙˆÙØ±. Ù‚Ù… Ø¨ØªØ«Ø¨ÙŠØªÙ‡ Ø£ÙˆÙ„Ø§Ù‹")
            return False

        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©
        await self._load_historical_data()

        self.is_initialized = True
        logger.info("ðŸ” Sentiment Analyzer initialized")
        return True

    async def analyze_text(self, text: str, source: str = "unknown") -> SentimentResult:
        """ØªØ­Ù„ÙŠÙ„ Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ù†Øµ"""

        if not self.is_initialized:
            raise RuntimeError("Sentiment Analyzer not initialized")

        if not TEXTBLOB_AVAILABLE:
            raise RuntimeError("TextBlob not available")

        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… TextBlob
        blob = TextBlob(text)
        polarity = blob.sentiment.polarity
        subjectivity = blob.sentiment.subjectivity

        # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
        if polarity > 0.1:
            sentiment = SentimentType.POSITIVE
        elif polarity < -0.1:
            sentiment = SentimentType.NEGATIVE
        else:
            sentiment = SentimentType.NEUTRAL

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø«Ù‚Ø© (Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙˆØ© Ø§Ù„Ù…Ø·Ù„Ù‚Ø©)
        confidence = min(abs(polarity) * 2, 1.0)

        result = SentimentResult(
            text=text,
            sentiment=sentiment,
            polarity=polarity,
            subjectivity=subjectivity,
            confidence=confidence,
            timestamp=datetime.utcnow(),
            source=source
        )

        # Ø­ÙØ¸ Ø§Ù„Ù†ØªÙŠØ¬Ø©
        await self._save_result(result)
        self.analysis_history.append(result)

        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
        await self._update_metrics(result)

        logger.info("ðŸ“Š Text analyzed",
                   sentiment=sentiment.value,
                   polarity=polarity,
                   confidence=confidence,
                   source=source)

        return result

    async def analyze_batch(self, texts: List[Dict[str, str]]) -> List[SentimentResult]:
        """ØªØ­Ù„ÙŠÙ„ Ø¯ÙØ¹Ø© Ù…Ù† Ø§Ù„Ù†ØµÙˆØµ"""

        results = []
        for text_data in texts:
            text = text_data.get("text", "")
            source = text_data.get("source", "batch")

            if text.strip():
                result = await self.analyze_text(text, source)
                results.append(result)

        return results

    async def get_sentiment_trends(self, hours: int = 24) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø§Ù„Ù…Ø´Ø§Ø¹Ø±"""

        # ØªØµÙÙŠØ© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø­Ø³Ø¨ Ø§Ù„ÙˆÙ‚Øª
        cutoff_time = datetime.utcnow().replace(hour=datetime.utcnow().hour - hours)
        recent_results = [r for r in self.analysis_history if r.timestamp > cutoff_time]

        if not recent_results:
            return {"message": "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ù„ØªØ­Ù„ÙŠÙ„"}

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        total = len(recent_results)
        positive = len([r for r in recent_results if r.sentiment == SentimentType.POSITIVE])
        negative = len([r for r in recent_results if r.sentiment == SentimentType.NEGATIVE])
        neutral = len([r for r in recent_results if r.sentiment == SentimentType.NEUTRAL])

        avg_polarity = sum(r.polarity for r in recent_results) / total
        avg_subjectivity = sum(r.subjectivity for r in recent_results) / total

        return {
            "period_hours": hours,
            "total_analyzed": total,
            "sentiment_distribution": {
                "positive": positive,
                "negative": negative,
                "neutral": neutral,
                "positive_percentage": (positive / total) * 100,
                "negative_percentage": (negative / total) * 100,
                "neutral_percentage": (neutral / total) * 100
            },
            "averages": {
                "polarity": avg_polarity,
                "subjectivity": avg_subjectivity
            },
            "trends": await self._calculate_trends(recent_results)
        }

    async def get_customer_insights(self) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø±Ø¤Ù‰ Ø­ÙˆÙ„ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡"""

        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø§Ù„Ø³Ù„Ø¨ÙŠØ©
        negative_feedback = [r for r in self.analysis_history
                           if r.sentiment == SentimentType.NEGATIVE and r.confidence > 0.5]

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© ÙÙŠ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø§Ù„Ø³Ù„Ø¨ÙŠØ©
        negative_words = await self._extract_common_words(negative_feedback)

        # Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ù„Ù„ØªØ­Ø³ÙŠÙ†
        recommendations = await self._generate_improvement_recommendations(negative_feedback)

        return {
            "negative_feedback_count": len(negative_feedback),
            "common_negative_words": negative_words,
            "improvement_recommendations": recommendations,
            "customer_satisfaction_score": await self._calculate_satisfaction_score()
        }

    def get_sentiment_metrics(self) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ù‚Ø§ÙŠÙŠØ³ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±"""
        return {
            "metrics": {
                "total_analyzed": self.metrics.total_analyzed,
                "sentiment_distribution": {
                    "positive": self.metrics.positive_count,
                    "negative": self.metrics.negative_count,
                    "neutral": self.metrics.neutral_count
                },
                "averages": {
                    "polarity": self.metrics.average_polarity,
                    "subjectivity": self.metrics.average_subjectivity
                }
            },
            "last_updated": self.metrics.last_updated.isoformat() if self.metrics.last_updated else None
        }

    async def _save_result(self, result: SentimentResult):
        """Ø­ÙØ¸ Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙÙŠ Redis"""
        try:
            redis = await get_redis()
            key = f"sentiment:{result.timestamp.isoformat()}"
            data = {
                "text": result.text[:200],  # Ø§Ù‚ØªØµØ§Ø± Ø§Ù„Ù†Øµ
                "sentiment": result.sentiment.value,
                "polarity": result.polarity,
                "subjectivity": result.subjectivity,
                "confidence": result.confidence,
                "source": result.source,
                "timestamp": result.timestamp.isoformat()
            }
            await redis.setex(key, 86400 * 30, str(data))  # 30 ÙŠÙˆÙ…
        except Exception as e:
            logger.warning("Failed to save sentiment result", error=str(e))

    async def _load_historical_data(self):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©"""
        try:
            redis = await get_redis()
            # ØªØ­Ù…ÙŠÙ„ Ø¢Ø®Ø± 100 Ù†ØªÙŠØ¬Ø©
            keys = await redis.keys("sentiment:*")
            if keys:
                recent_keys = sorted(keys, reverse=True)[:100]
                for key in recent_keys:
                    data_str = await redis.get(key)
                    if data_str:
                        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ù…Ø¨Ø³Ø·)
                        self.metrics.total_analyzed += 1
        except Exception as e:
            logger.warning("Failed to load historical sentiment data", error=str(e))

    async def _update_metrics(self, result: SentimentResult):
        """ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³"""
        self.metrics.total_analyzed += 1

        if result.sentiment == SentimentType.POSITIVE:
            self.metrics.positive_count += 1
        elif result.sentiment == SentimentType.NEGATIVE:
            self.metrics.negative_count += 1
        else:
            self.metrics.neutral_count += 1

        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ø¹Ø¯Ù„Ø§Øª
        total = self.metrics.total_analyzed
        self.metrics.average_polarity = (
            (self.metrics.average_polarity * (total - 1)) + result.polarity
        ) / total
        self.metrics.average_subjectivity = (
            (self.metrics.average_subjectivity * (total - 1)) + result.subjectivity
        ) / total

        self.metrics.last_updated = datetime.utcnow()

    async def _calculate_trends(self, results: List[SentimentResult]) -> Dict[str, Any]:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª"""
        if len(results) < 2:
            return {"trend": "insufficient_data"}

        # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„ÙˆÙ‚Øª
        sorted_results = sorted(results, key=lambda x: x.timestamp)

        # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØºÙŠÙŠØ± ÙÙŠ Ø§Ù„Ù…ØªÙˆØ³Ø·
        mid_point = len(sorted_results) // 2
        first_half = sorted_results[:mid_point]
        second_half = sorted_results[mid_point:]

        first_avg = sum(r.polarity for r in first_half) / len(first_half) if first_half else 0
        second_avg = sum(r.polarity for r in second_half) / len(second_half) if second_half else 0

        trend = "stable"
        if second_avg > first_avg + 0.1:
            trend = "improving"
        elif second_avg < first_avg - 0.1:
            trend = "declining"

        return {
            "trend": trend,
            "change": second_avg - first_avg,
            "first_half_avg": first_avg,
            "second_half_avg": second_avg
        }

    async def _extract_common_words(self, results: List[SentimentResult]) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© Ù…Ù† Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø§Ù„Ø³Ù„Ø¨ÙŠØ©"""
        if not TEXTBLOB_AVAILABLE or not results:
            return []

        all_words = []
        for result in results:
            blob = TextBlob(result.text)
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø§Ø³Ù…ÙŠØ© ÙˆØ§Ù„ØµÙØ§Øª
            words = [word.lower() for word, tag in blob.tags
                    if tag in ['NN', 'NNS', 'JJ', 'JJR', 'JJS'] and len(word) > 3]
            all_words.extend(words)

        # Ø¹Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª
        word_counts = {}
        for word in all_words:
            word_counts[word] = word_counts.get(word, 0) + 1

        # Ø¥Ø±Ø¬Ø§Ø¹ Ø£ÙƒØ«Ø± 10 ÙƒÙ„Ù…Ø§Øª Ø´ÙŠÙˆØ¹Ø§Ù‹
        return sorted(word_counts.items(), key=lambda x: x[1], reverse=True)[:10]

    async def _generate_improvement_recommendations(self, negative_results: List[SentimentResult]) -> List[str]:
        """ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ù„Ù„ØªØ­Ø³ÙŠÙ†"""
        recommendations = []

        if not negative_results:
            return ["Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø³Ù„Ø¨ÙŠØ© ÙƒØ§ÙÙŠØ© Ù„ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª"]

        # ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø´ÙƒØ§ÙˆÙ‰
        common_words = await self._extract_common_words(negative_results)

        # ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
        word_to_recommendation = {
            "shipping": "ØªØ­Ø³ÙŠÙ† Ø®Ø¯Ù…Ø© Ø§Ù„Ø´Ø­Ù† ÙˆØªÙ‚Ù„ÙŠÙ„ Ø£ÙˆÙ‚Ø§Øª Ø§Ù„ØªØ³Ù„ÙŠÙ…",
            "delivery": "ØªØ­Ø³ÙŠÙ† Ø¯Ù‚Ø© Ù…ÙˆØ§Ø¹ÙŠØ¯ Ø§Ù„ØªØ³Ù„ÙŠÙ…",
            "quality": "ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª",
            "price": "Ù…Ø±Ø§Ø¬Ø¹Ø© Ø³ÙŠØ§Ø³Ø© Ø§Ù„ØªØ³Ø¹ÙŠØ±",
            "service": "ØªØ­Ø³ÙŠÙ† Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡",
            "packaging": "ØªØ­Ø³ÙŠÙ† ØªØºÙ„ÙŠÙ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª",
            "size": "ØªØ­Ø³ÙŠÙ† Ø¯Ù‚Ø© Ø£Ø­Ø¬Ø§Ù… Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª",
            "return": "ØªØ¨Ø³ÙŠØ· Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø¥Ø±Ø¬Ø§Ø¹",
            "communication": "ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡"
        }

        for word, count in common_words:
            if word in word_to_recommendation:
                recommendations.append(word_to_recommendation[word])

        if not recommendations:
            recommendations.append("ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ ÙˆØ¬Ù…Ø¹ Ù…Ù„Ø§Ø­Ø¸Ø§ØªÙ‡Ù… Ø¨Ø§Ù†ØªØ¸Ø§Ù…")

        return recommendations[:5]  # Ø£Ù‚ØµÙ‰ 5 ØªÙˆØµÙŠØ§Øª

    async def _calculate_satisfaction_score(self) -> float:
        """Ø­Ø³Ø§Ø¨ Ø¯Ø±Ø¬Ø© Ø±Ø¶Ø§ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡"""
        if self.metrics.total_analyzed == 0:
            return 0.0

        # Ø¯Ø±Ø¬Ø© Ø§Ù„Ø±Ø¶Ø§ = (Ø¥ÙŠØ¬Ø§Ø¨ÙŠ + Ù…Ø­Ø§ÙŠØ¯/2) / Ø¥Ø¬Ù…Ø§Ù„ÙŠ
        positive_weight = self.metrics.positive_count
        neutral_weight = self.metrics.neutral_count * 0.5

        satisfaction = (positive_weight + neutral_weight) / self.metrics.total_analyzed
        return min(satisfaction * 100, 100.0)  # ÙƒÙ†Ø³Ø¨Ø© Ù…Ø¦ÙˆÙŠØ©