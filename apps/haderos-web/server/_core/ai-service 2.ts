// @ts-nocheck
// server/_core/ai-service.ts
import { TRPCError } from '@trpc/server';
import { invokeLLM } from './llm';

export enum AIProvider {
  MANUS = 'manus',      // Ù…Ø¬Ø§Ù†ÙŠ (Ù…Ø¯Ù…Ø¬ ÙÙŠ Manus)
  DEEPSEEK = 'deepseek', // Ø±Ø®ÙŠØµ ÙˆØ³Ø±ÙŠØ¹
  CLAUDE = 'claude',     // Ù…ØªÙ‚Ø¯Ù… ÙˆØ¥Ø¨Ø¯Ø§Ø¹ÙŠ
}

export type AIOptions = {
  provider?: AIProvider;
  autoSelect?: boolean;
  maxCost?: number;
  timeout?: number;
  fallback?: boolean;
  model?: string;
  temperature?: number;
};

export type AIResponse = {
  provider: AIProvider;
  content: string;
  cost: number;
  usage: any;
  latency: number;
  model?: string;
};

export class UnifiedAIService {
  private startTime: number = 0;

  constructor() {}

  // ========== CORE AI PROVIDERS ==========

  // 1. Manus invokeLLM (Ø§Ù„Ù…Ø¬Ø§Ù†ÙŠ ÙˆØ§Ù„Ù…Ø¶Ù…ÙˆÙ†)
  async invokeManusLLM(
    messages: any[],
    options: { model?: string; temperature?: number } = {}
  ): Promise<AIResponse> {
    this.startTimer();
    
    try {
      console.log('ğŸ¤– Using Manus invokeLLM (Free Tier)...');
      
      const response = await invokeLLM({
        messages,
        temperature: options.temperature || 0.7,
      });

      const content = response.choices[0]?.message?.content || '';

      return {
        provider: AIProvider.MANUS,
        content: typeof content === 'string' ? content : JSON.stringify(content),
        cost: 0, // Ù…Ø¬Ø§Ù†ÙŠ ØªÙ…Ø§Ù…Ø§Ù‹
        usage: response.usage || { tokens: 0 },
        latency: this.getLatency(),
        model: response.model || 'deepseek-chat'
      };
    } catch (error: any) {
      console.error('âŒ Manus LLM Error:', error);
      throw new TRPCError({
        code: 'INTERNAL_SERVER_ERROR',
        message: `Manus invokeLLM failed: ${error.message}`
      });
    }
  }

  // 2. DeepSeek API (Ø±Ø®ÙŠØµ ÙˆØ³Ø±ÙŠØ¹ - Ù…Ù…ØªØ§Ø² Ù„Ù„ÙƒÙˆØ¯)
  async invokeDeepSeek(
    messages: any[],
    options: { model?: string; temperature?: number } = {}
  ): Promise<AIResponse> {
    this.startTimer();
    
    const apiKey = process.env.DEEPSEEK_API_KEY;
    if (!apiKey) {
      throw new TRPCError({
        code: 'BAD_REQUEST',
        message: 'DEEPSEEK_API_KEY not configured in environment variables'
      });
    }

    try {
      console.log('ğŸš€ Using DeepSeek API (Cost-effective)...');
      
      const response = await fetch('https://api.deepseek.com/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json',
          'Accept': 'application/json'
        },
        body: JSON.stringify({
          model: options.model || 'deepseek-chat',
          messages,
          temperature: options.temperature || 0.7,
          max_tokens: 2000,
          stream: false
        })
      });

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`DeepSeek API error ${response.status}: ${errorText}`);
      }

      const data = await response.json();
      
      if (!data.choices || !data.choices[0]) {
        throw new Error('Invalid response format from DeepSeek API');
      }

      return {
        provider: AIProvider.DEEPSEEK,
        content: data.choices[0].message.content,
        cost: this.calculateDeepSeekCost(data.usage || {}),
        usage: data.usage || {},
        latency: this.getLatency(),
        model: options.model || 'deepseek-chat'
      };
    } catch (error: any) {
      console.error('âŒ DeepSeek API Error:', error);
      throw new TRPCError({
        code: 'INTERNAL_SERVER_ERROR',
        message: `DeepSeek API failed: ${error.message}`
      });
    }
  }

  // 3. Claude API (Ù…ØªÙ‚Ø¯Ù… - Ù„Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©)
  async invokeClaude(
    messages: any[],
    options: { model?: string; maxTokens?: number } = {}
  ): Promise<AIResponse> {
    this.startTimer();
    
    const apiKey = process.env.CLAUDE_API_KEY;
    if (!apiKey) {
      throw new TRPCError({
        code: 'BAD_REQUEST',
        message: 'CLAUDE_API_KEY not configured in environment variables'
      });
    }

    try {
      console.log('ğŸ¯ Using Claude API (Advanced tasks)...');
      
      // ØªØ­ÙˆÙŠÙ„ ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ù„ÙŠÙƒÙˆÙ† Ù…ØªÙˆØ§ÙÙ‚Ø§Ù‹ Ù…Ø¹ Claude
      const claudeMessages = messages
        .filter(msg => msg.role !== 'system')
        .map(msg => ({
          role: msg.role as 'user' | 'assistant',
          content: msg.content
        }));

      const systemMessage = messages.find(msg => msg.role === 'system')?.content || 
        'You are a helpful AI assistant that speaks Arabic fluently.';

      const response = await fetch('https://api.anthropic.com/v1/messages', {
        method: 'POST',
        headers: {
          'x-api-key': apiKey,
          'anthropic-version': '2023-06-01',
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          model: options.model || 'claude-3-sonnet-20240229',
          max_tokens: options.maxTokens || 1000,
          messages: claudeMessages,
          system: systemMessage
        })
      });

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`Claude API error ${response.status}: ${errorText}`);
      }

      const data = await response.json();
      
      if (!data.content || !data.content[0]) {
        throw new Error('Invalid response format from Claude API');
      }

      return {
        provider: AIProvider.CLAUDE,
        content: data.content[0].text,
        cost: this.calculateClaudeCost(data.usage || {}),
        usage: data.usage || {},
        latency: this.getLatency(),
        model: options.model || 'claude-3-sonnet-20240229'
      };
    } catch (error: any) {
      console.error('âŒ Claude API Error:', error);
      throw new TRPCError({
        code: 'INTERNAL_SERVER_ERROR',
        message: `Claude API failed: ${error.message}`
      });
    }
  }

  // ========== SMART ROUTER ==========

  async generateResponse(
    messages: any[],
    options: AIOptions = {}
  ): Promise<AIResponse> {
    const {
      provider,
      autoSelect = true,
      maxCost = 0.1, // $0.10 ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰
      fallback = true,
      model = 'auto',
      temperature = 0.7
    } = options;

    console.log('ğŸ§  Unified AI Service - Processing request...');
    console.log(`   Auto-select: ${autoSelect}, Max cost: $${maxCost}, Fallback: ${fallback}`);

    // Ø¥Ø°Ø§ Ø­Ø¯Ø¯ provider Ù…Ø­Ø¯Ø¯ØŒ Ø§Ø³ØªØ®Ø¯Ù…Ù‡ Ù…Ø¨Ø§Ø´Ø±Ø©
    if (provider && !autoSelect) {
      console.log(`ğŸ¯ Using specified provider: ${provider}`);
      return this.invokeProvider(provider, messages, { model, temperature });
    }

    // Ø§Ù„Ø°ÙƒÙŠ: Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ provider Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù‡Ù…Ø© ÙˆØ§Ù„ØªÙƒÙ„ÙØ©
    const selectedProvider = this.selectSmartProvider(
      messages[messages.length - 1]?.content || '',
      maxCost,
      model
    );
    
    console.log(`ğŸ¤– Smart router selected: ${selectedProvider}`);

    try {
      return await this.invokeProvider(selectedProvider, messages, { model, temperature });
    } catch (error) {
      // Fallback ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¥Ø°Ø§ ÙØ´Ù„ Provider
      if (fallback) {
        console.warn(`âš ï¸ Provider ${selectedProvider} failed, trying fallback...`);
        return this.fallbackProvider(selectedProvider, messages, { model, temperature });
      }
      throw error;
    }
  }

  // ========== INTELLIGENT PROVIDER SELECTION ==========

  private selectSmartProvider(
    userMessage: string,
    maxCost: number,
    model: string
  ): AIProvider {
    const message = userMessage.toLowerCase();
    
    // 1. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ù‡Ù…Ø© Ø¨Ø³ÙŠØ·Ø© â†’ Manus (Ù…Ø¬Ø§Ù†ÙŠ)
    if (this.isSimpleTask(message)) {
      console.log('ğŸ“ Task type: Simple â†’ Manus (Free)');
      return AIProvider.MANUS;
    }

    // 2. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ù‡Ù…Ø© Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ø§Ù„Ø¨Ø±Ù…Ø¬Ø© â†’ DeepSeek (Ù…Ù…ØªØ§Ø² Ù„Ù„ÙƒÙˆØ¯)
    if (this.isCodeTask(message) && process.env.DEEPSEEK_API_KEY) {
      console.log('ğŸ’» Task type: Coding â†’ DeepSeek (Best for code)');
      return AIProvider.DEEPSEEK;
    }

    // 3. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ù‡Ù…Ø© Ø¥Ø¨Ø¯Ø§Ø¹ÙŠØ© ÙˆÙ…Ø¹Ù‚Ø¯Ø© â†’ Claude (Ø¥Ø°Ø§ Ø³Ù…Ø­Øª Ø§Ù„ØªÙƒÙ„ÙØ©)
    if (this.isCreativeTask(message) && maxCost >= 0.1 && process.env.CLAUDE_API_KEY) {
      console.log('ğŸ¨ Task type: Creative/Complex â†’ Claude (Premium)');
      return AIProvider.CLAUDE;
    }

    // 4. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ù‡Ù…Ø© ØªØ­Ù„ÙŠÙ„ÙŠØ© â†’ DeepSeek (Ø¬ÙŠØ¯ ÙˆØ³Ø±ÙŠØ¹)
    if (this.isAnalyticalTask(message) && maxCost >= 0.01 && process.env.DEEPSEEK_API_KEY) {
      console.log('ğŸ” Task type: Analytical â†’ DeepSeek (Fast & accurate)');
      return AIProvider.DEEPSEEK;
    }

    // 5. Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ: Manus (Ù…Ø¬Ø§Ù†ÙŠ)
    console.log('âš¡ Default: Manus (Free & reliable)');
    return AIProvider.MANUS;
  }

  // ========== TASK DETECTION ==========

  private isSimpleTask(message: string): boolean {
    const simplePatterns = [
      /^(Ù…Ø±Ø­Ø¨Ø§|hello|hi|Ø§Ù‡Ù„Ø§|Ø§Ù„Ø³Ù„Ø§Ù…)/i,
      /^(ÙƒÙŠÙ Ø­Ø§Ù„Ùƒ|how are you)/i,
      /^(Ù…Ø§ Ø§Ø³Ù…Ùƒ|who are you)/i,
      /^(Ø´ÙƒØ±Ø§|thank you|Ù…Ù…ØªØ§Ø²)/i,
      /^(Ø¨Ø³ÙŠØ·|simple|Ø³Ø¤Ø§Ù„ Ø¨Ø³ÙŠØ·)/i,
      /^(Ù†Ø¹Ù…|yes|Ù„Ø§|no|ok|Ø­Ø³Ù†Ø§)/i
    ];
    return simplePatterns.some(pattern => pattern.test(message));
  }

  private isCodeTask(message: string): boolean {
    const codePatterns = [
      /(ÙƒÙˆØ¯|code|Ø¨Ø±Ù†Ø§Ù…Ø¬|program)/i,
      /(Ø¯Ø§Ù„Ø©|function|class|ÙˆØ§Ø¬Ù‡Ø©)/i,
      /(javascript|typescript|python|java|php|html|css)/i,
      /(bug|error|Ø®Ø·Ø£|ØªØµØ­ÙŠØ­)/i,
      /(Ù…ÙƒØªØ¨Ø©|library|package|npm|yarn)/i,
      /(Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ©|algorithm|Ø¨Ù†ÙŠØ© Ø¨ÙŠØ§Ù†Ø§Øª)/i
    ];
    return codePatterns.some(pattern => pattern.test(message));
  }

  private isCreativeTask(message: string): boolean {
    const creativePatterns = [
      /(Ù‚ØµØ©|story|Ø±ÙˆØ§ÙŠØ©)/i,
      /(Ø´Ø¹Ø±|poem|Ù‚ØµÙŠØ¯Ø©)/i,
      /(Ø¥Ø¨Ø¯Ø§Ø¹|creative|ØªØ®ÙŠÙ„|imagine)/i,
      /(ØªØ®Ø·ÙŠØ·|planning|Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©|strategy)/i,
      /(ØªØµÙ…ÙŠÙ…|design|art|ÙÙ†)/i,
      /(Ø§Ø¨ØªÙƒØ§Ø±|innovation|Ø¬Ø¯ÙŠØ¯|new idea)/i
    ];
    return creativePatterns.some(pattern => pattern.test(message));
  }

  private isAnalyticalTask(message: string): boolean {
    const analyticalPatterns = [
      /(Ø­Ù„Ù„|analyze|ØªØ­Ù„ÙŠÙ„)/i,
      /(Ù‚Ø§Ø±Ù†|compare|comparison)/i,
      /(Ø¨Ø­Ø«|research|study)/i,
      /(Ø´Ø±Ø­|explain|explanations)/i,
      /(Ø±Ø£ÙŠÙƒ|opinion|Ù†ØµÙŠØ­Ø©|advice)/i,
      /(ØªÙ‚ÙŠÙŠÙ…|evaluate|assessment)/i
    ];
    return analyticalPatterns.some(pattern => pattern.test(message));
  }

  // ========== HELPER METHODS ==========

  private async invokeProvider(
    provider: AIProvider,
    messages: any[],
    options: { model?: string; temperature?: number }
  ): Promise<AIResponse> {
    switch (provider) {
      case AIProvider.MANUS:
        return this.invokeManusLLM(messages, {
          model: options.model === 'auto' ? 'deepseek-chat' : options.model,
          temperature: options.temperature
        });
      case AIProvider.DEEPSEEK:
        return this.invokeDeepSeek(messages, {
          model: options.model === 'auto' ? 'deepseek-chat' : options.model,
          temperature: options.temperature
        });
      case AIProvider.CLAUDE:
        return this.invokeClaude(messages, {
          model: options.model === 'auto' ? 'claude-3-sonnet-20240229' : options.model
        });
      default:
        throw new TRPCError({
          code: 'BAD_REQUEST',
          message: `Unknown provider: ${provider}`
        });
    }
  }

  private async fallbackProvider(
    failedProvider: AIProvider,
    messages: any[],
    options: { model?: string; temperature?: number }
  ): Promise<AIResponse> {
    // ØªØ±ØªÙŠØ¨ Fallback (Ø§Ù„Ù…Ø¬Ø§Ù†ÙŠ Ø£ÙˆÙ„Ø§Ù‹)
    const fallbackOrder = [
      AIProvider.MANUS,    // Ù…Ø¬Ø§Ù†ÙŠ ÙˆÙ…Ø¶Ù…ÙˆÙ†
      AIProvider.DEEPSEEK, // Ø±Ø®ÙŠØµ
      AIProvider.CLAUDE    // Ù…ØªÙ‚Ø¯Ù…
    ].filter(p => p !== failedProvider);

    for (const provider of fallbackOrder) {
      try {
        console.log(`ğŸ”„ Trying fallback: ${provider}`);
        return await this.invokeProvider(provider, messages, options);
      } catch (error: any) {
        console.log(`âŒ Fallback ${provider} also failed:`, error.message);
        // Ø§Ø³ØªÙ…Ø± ÙÙŠ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø¹ Provider Ø§Ù„ØªØ§Ù„ÙŠ
      }
    }

    throw new TRPCError({
      code: 'INTERNAL_SERVER_ERROR',
      message: 'All AI providers failed. Please check your API keys and internet connection.'
    });
  }

  // ========== COST CALCULATION ==========

  private calculateDeepSeekCost(usage: any): number {
    // DeepSeek pricing: $0.14 per 1M tokens
    const inputTokens = usage.prompt_tokens || 0;
    const outputTokens = usage.completion_tokens || 0;
    const totalTokens = inputTokens + outputTokens;
    
    return (totalTokens / 1000000) * 0.14;
  }

  private calculateClaudeCost(usage: any): number {
    // Claude Sonnet pricing: $3 per 1M input, $15 per 1M output
    const inputTokens = usage.input_tokens || 0;
    const outputTokens = usage.output_tokens || 0;
    
    const inputCost = (inputTokens / 1000000) * 3;
    const outputCost = (outputTokens / 1000000) * 15;
    
    return inputCost + outputCost;
  }

  // ========== PERFORMANCE MONITORING ==========

  private startTimer(): void {
    this.startTime = Date.now();
  }

  private getLatency(): number {
    return Date.now() - this.startTime;
  }

  // ========== UTILITY METHODS ==========

  getAvailableProviders(): AIProvider[] {
    const providers: AIProvider[] = [AIProvider.MANUS];
    
    if (process.env.DEEPSEEK_API_KEY) {
      providers.push(AIProvider.DEEPSEEK);
    }
    
    if (process.env.CLAUDE_API_KEY) {
      providers.push(AIProvider.CLAUDE);
    }
    
    return providers;
  }

  getProviderInfo(provider: AIProvider) {
    const info = {
      [AIProvider.MANUS]: {
        name: 'Manus invokeLLM',
        cost: 'Free',
        bestFor: 'Simple queries, greetings, basic tasks',
        maxTokens: 2000
      },
      [AIProvider.DEEPSEEK]: {
        name: 'DeepSeek API',
        cost: '$0.14 per 1M tokens',
        bestFor: 'Code generation, analysis, technical tasks',
        maxTokens: 2000
      },
      [AIProvider.CLAUDE]: {
        name: 'Claude API',
        cost: '$3-15 per 1M tokens',
        bestFor: 'Creative writing, complex analysis, strategy',
        maxTokens: 1000
      }
    };
    
    return info[provider] || { name: 'Unknown', cost: 'N/A', bestFor: 'N/A', maxTokens: 0 };
  }
}
